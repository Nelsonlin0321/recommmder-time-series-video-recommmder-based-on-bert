{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import model_config\n",
    "from model import VedioRecommender\n",
    "from dataset import ViewDataSet\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from adamp import AdamP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VedioRecommender(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Read Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_dataset = utils.open_object(\"./artifacts/df_agg_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_duration</th>\n",
       "      <th>device_first_visit_age</th>\n",
       "      <th>user_age</th>\n",
       "      <th>video_start_hour</th>\n",
       "      <th>video_end_hour</th>\n",
       "      <th>platform_name</th>\n",
       "      <th>user_type</th>\n",
       "      <th>subscription_source</th>\n",
       "      <th>plan_platform</th>\n",
       "      <th>resolution</th>\n",
       "      <th>...</th>\n",
       "      <th>video_streaming_mode</th>\n",
       "      <th>cp_name</th>\n",
       "      <th>product_cat_name</th>\n",
       "      <th>product_lang_name</th>\n",
       "      <th>product_series_cms_id</th>\n",
       "      <th>next_sri_des</th>\n",
       "      <th>hist_sri_des</th>\n",
       "      <th>user_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.491445</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.991258</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.557971</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[31, 31, 31, 31, 31]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1, 1, 1, 1, 2]</td>\n",
       "      <td>[12, 12, 12, 12, 38, 36]</td>\n",
       "      <td>[16, 16, 16, 16, 17, 39]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[508, 508, 508, 508, 1094, 924]</td>\n",
       "      <td>Ashes of Love: Four thousand years ago when Ji...</td>\n",
       "      <td>sri_des 1: The Return of Superman (2021): The ...</td>\n",
       "      <td>00189c7eddbe8fa8b0eb6cb6d27d4ee0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.491445</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.991258</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.557971</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[31, 31, 31, 31, 31]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1, 1, 1, 1, 2]</td>\n",
       "      <td>[12, 12, 12, 12, 38, 28]</td>\n",
       "      <td>[16, 16, 16, 16, 17, 29]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0]</td>\n",
       "      <td>[508, 508, 508, 508, 1094, 801]</td>\n",
       "      <td>Gonjiam Haunted Asylum: 在网路广播节目剧组的召集下，數名青年一同進入...</td>\n",
       "      <td>sri_des 1: The Return of Superman (2021): The ...</td>\n",
       "      <td>00189c7eddbe8fa8b0eb6cb6d27d4ee0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491445</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.991258</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.557971</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[31, 31, 31, 31, 31]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1, 1, 1, 1, 2]</td>\n",
       "      <td>[12, 12, 12, 12, 38, 34]</td>\n",
       "      <td>[16, 16, 16, 16, 17, 38]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[508, 508, 508, 508, 1094, 1424]</td>\n",
       "      <td>Look For A Star (SVOD): It’s hardly a coincide...</td>\n",
       "      <td>sri_des 1: The Return of Superman (2021): The ...</td>\n",
       "      <td>00189c7eddbe8fa8b0eb6cb6d27d4ee0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.459936</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.991258</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.572464</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[31, 31, 31, 31, 31]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1, 1, 1, 2, 2]</td>\n",
       "      <td>[12, 12, 12, 38, 38, 56]</td>\n",
       "      <td>[16, 16, 16, 17, 17, 17]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[508, 508, 508, 1094, 169, 660]</td>\n",
       "      <td>The Penthouse Special: The Penthouse is a plac...</td>\n",
       "      <td>sri_des 1: The Return of Superman (2021): The ...</td>\n",
       "      <td>00189c7eddbe8fa8b0eb6cb6d27d4ee0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.430993</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.991258</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.579710</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[31, 31, 31, 31, 31]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1, 1, 2, 2, 2]</td>\n",
       "      <td>[12, 12, 38, 38, 16, 7]</td>\n",
       "      <td>[16, 16, 17, 17, 17, 35]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[508, 508, 1094, 169, 984, 1407]</td>\n",
       "      <td>My Forever Sunshine: The story about Paeng, a ...</td>\n",
       "      <td>sri_des 1: The Return of Superman (2021): The ...</td>\n",
       "      <td>00189c7eddbe8fa8b0eb6cb6d27d4ee0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_duration  device_first_visit_age  user_age  video_start_hour  \\\n",
       "0          0.491445                 0.15625  0.991258          0.536232   \n",
       "1          0.491445                 0.15625  0.991258          0.536232   \n",
       "2          0.491445                 0.15625  0.991258          0.536232   \n",
       "3          0.459936                 0.15625  0.991258          0.550725   \n",
       "4          0.430993                 0.15625  0.991258          0.565217   \n",
       "\n",
       "   video_end_hour    platform_name        user_type subscription_source  \\\n",
       "0        0.557971  [3, 3, 3, 3, 3]  [1, 1, 1, 1, 1]     [0, 0, 0, 0, 0]   \n",
       "1        0.557971  [3, 3, 3, 3, 3]  [1, 1, 1, 1, 1]     [0, 0, 0, 0, 0]   \n",
       "2        0.557971  [3, 3, 3, 3, 3]  [1, 1, 1, 1, 1]     [0, 0, 0, 0, 0]   \n",
       "3        0.572464  [3, 3, 3, 3, 3]  [1, 1, 1, 1, 1]     [0, 0, 0, 0, 0]   \n",
       "4        0.579710  [3, 3, 3, 3, 3]  [1, 1, 1, 1, 1]     [0, 0, 0, 0, 0]   \n",
       "\n",
       "          plan_platform       resolution  ... video_streaming_mode  \\\n",
       "0  [31, 31, 31, 31, 31]  [0, 0, 0, 0, 0]  ...      [1, 1, 1, 1, 2]   \n",
       "1  [31, 31, 31, 31, 31]  [0, 0, 0, 0, 0]  ...      [1, 1, 1, 1, 2]   \n",
       "2  [31, 31, 31, 31, 31]  [0, 0, 0, 0, 0]  ...      [1, 1, 1, 1, 2]   \n",
       "3  [31, 31, 31, 31, 31]  [0, 0, 0, 0, 0]  ...      [1, 1, 1, 2, 2]   \n",
       "4  [31, 31, 31, 31, 31]  [0, 0, 0, 0, 0]  ...      [1, 1, 2, 2, 2]   \n",
       "\n",
       "                    cp_name          product_cat_name   product_lang_name  \\\n",
       "0  [12, 12, 12, 12, 38, 36]  [16, 16, 16, 16, 17, 39]  [1, 1, 1, 1, 1, 1]   \n",
       "1  [12, 12, 12, 12, 38, 28]  [16, 16, 16, 16, 17, 29]  [1, 1, 1, 1, 1, 0]   \n",
       "2  [12, 12, 12, 12, 38, 34]  [16, 16, 16, 16, 17, 38]  [1, 1, 1, 1, 1, 1]   \n",
       "3  [12, 12, 12, 38, 38, 56]  [16, 16, 16, 17, 17, 17]  [1, 1, 1, 1, 1, 1]   \n",
       "4   [12, 12, 38, 38, 16, 7]  [16, 16, 17, 17, 17, 35]  [1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "              product_series_cms_id  \\\n",
       "0   [508, 508, 508, 508, 1094, 924]   \n",
       "1   [508, 508, 508, 508, 1094, 801]   \n",
       "2  [508, 508, 508, 508, 1094, 1424]   \n",
       "3   [508, 508, 508, 1094, 169, 660]   \n",
       "4  [508, 508, 1094, 169, 984, 1407]   \n",
       "\n",
       "                                        next_sri_des  \\\n",
       "0  Ashes of Love: Four thousand years ago when Ji...   \n",
       "1  Gonjiam Haunted Asylum: 在网路广播节目剧组的召集下，數名青年一同進入...   \n",
       "2  Look For A Star (SVOD): It’s hardly a coincide...   \n",
       "3  The Penthouse Special: The Penthouse is a plac...   \n",
       "4  My Forever Sunshine: The story about Paeng, a ...   \n",
       "\n",
       "                                        hist_sri_des  \\\n",
       "0  sri_des 1: The Return of Superman (2021): The ...   \n",
       "1  sri_des 1: The Return of Superman (2021): The ...   \n",
       "2  sri_des 1: The Return of Superman (2021): The ...   \n",
       "3  sri_des 1: The Return of Superman (2021): The ...   \n",
       "4  sri_des 1: The Return of Superman (2021): The ...   \n",
       "\n",
       "                            user_id sequence_id label  \n",
       "0  00189c7eddbe8fa8b0eb6cb6d27d4ee0           1     0  \n",
       "1  00189c7eddbe8fa8b0eb6cb6d27d4ee0           4     0  \n",
       "2  00189c7eddbe8fa8b0eb6cb6d27d4ee0           5     0  \n",
       "3  00189c7eddbe8fa8b0eb6cb6d27d4ee0           8     0  \n",
       "4  00189c7eddbe8fa8b0eb6cb6d27d4ee0          13     0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_5_features = ['platform_name', 'user_type',\n",
    "       'subscription_source', 'plan_platform', 'resolution', 'subtitle',\n",
    "       'screen_mode', 'device_network_mode', 'video_streaming_mode']\n",
    "\n",
    "sequence_6_features = ['cp_name','product_cat_name', 'product_lang_name', 'product_series_cms_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sequence_5_features:\n",
    "    df_agg_dataset = df_agg_dataset[df_agg_dataset[col].apply(lambda x:len(x)==5)] \n",
    "\n",
    "for col in sequence_6_features:\n",
    "    df_agg_dataset = df_agg_dataset[df_agg_dataset[col].apply(lambda x:len(x)==6)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test = train_test_split(df_agg_dataset,test_size=0.3,random_state=33,shuffle = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ViewDataSet(df_train)\n",
    "test_dataset = ViewDataSet(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=12, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCELoss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = inputs['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7262, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BCELoss(scores,labels.view(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamP(model.parameters(),lr=2e-4,\n",
    "                  betas=(0.9, 0.999), weight_decay=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_config:\n",
    "    epoches = 5\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model_save_dir = \"./artifacts/models\"\n",
    "    train_batch_size = 12\n",
    "    val_batch_size = int(train_batch_size*1.5)\n",
    "    eval_steps = (len(train_dataset)//train_batch_size)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/nelson/Codes/VideoRecommender/4-training.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.112.110.123/home/nelson/Codes/VideoRecommender/4-training.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mto(train_config\u001b[39m.\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    581\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    581\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    581\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "model = model.to(train_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_full_metrics(model,dataset_loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_list = []\n",
    "    labels_list = []\n",
    "    pred_list = []\n",
    "    prob_list = []\n",
    "\n",
    "    pbar = tqdm(total = len(dataset_loader),desc = \"Model Evaluating\",position=0, leave=True)\n",
    "\n",
    "\n",
    "    for inputs in dataset_loader:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            inputs = utils.to_device(inputs,train_config.device)\n",
    "            labels = inputs['label'].view(-1,1)\n",
    "            \n",
    "            probs = model(inputs)\n",
    "            \n",
    "            loss = BCELoss(probs,labels).item()\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            labels  = labels.detach().cpu().numpy()\n",
    "            labels_list.extend(labels.flatten())\n",
    "\n",
    "            probs = probs.detach().cpu().numpy()\n",
    "            prob_list.extend(probs.flatten())\n",
    "            pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    \n",
    "    auc = metrics.roc_auc_score(labels_list, prob_list)\n",
    "    recall, precision, thres = metrics.precision_recall_curve(labels_list, prob_list)\n",
    "    \n",
    "    \n",
    "    f1 = recall*precision*2 / (recall + precision)\n",
    "    f1_temp = f1\n",
    "    f1 = np.nan_to_num(f1,nan = -1)\n",
    "\n",
    "    arg = f1.argmax()\n",
    "    \n",
    "    best_thres = thres[arg]\n",
    "    best_f1 = f1[arg]\n",
    "    best_recall = recall[arg]\n",
    "    best_precision = precision[arg]\n",
    "    \n",
    "    pred_list = [1 if prob>=best_thres else 0 for prob in prob_list]\n",
    "    accuracy = metrics.accuracy_score(labels_list,pred_list)\n",
    "    \n",
    "    avg_loss = np.mean(loss_list)\n",
    "    \n",
    "    result = {\"threshold\":best_thres,\n",
    "              \"accuracy\":accuracy,\n",
    "              \"recall\":best_recall,\n",
    "              \"precision\":best_precision,\n",
    "              \"f1\":best_f1,'auc':auc,\n",
    "              'eval_loss':avg_loss} \n",
    "\n",
    "    return result,prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_config.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Evaluating:   0%|          | 0/4870 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/nelson/Codes/VideoRecommender/4-training.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.112.110.123/home/nelson/Codes/VideoRecommender/4-training.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m result,prob_list \u001b[39m=\u001b[39m evaluate_full_metrics(model,test_loader)\n",
      "\u001b[1;32m/home/nelson/Codes/VideoRecommender/4-training.ipynb Cell 29\u001b[0m in \u001b[0;36mevaluate_full_metrics\u001b[0;34m(model, dataset_loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.112.110.123/home/nelson/Codes/VideoRecommender/4-training.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs \u001b[39min\u001b[39;00m dataset_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.112.110.123/home/nelson/Codes/VideoRecommender/4-training.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.112.110.123/home/nelson/Codes/VideoRecommender/4-training.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m         inputs \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mto_device(inputs,train_config\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.112.110.123/home/nelson/Codes/VideoRecommender/4-training.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m         labels \u001b[39m=\u001b[39m inputs[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.112.110.123/home/nelson/Codes/VideoRecommender/4-training.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m         probs \u001b[39m=\u001b[39m model(inputs)\n",
      "File \u001b[0;32m~/Codes/VideoRecommender/utils.py:15\u001b[0m, in \u001b[0;36mto_device\u001b[0;34m(inputs, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_device\u001b[39m(inputs,device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     14\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs,\u001b[39mdict\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m         inputs \u001b[39m=\u001b[39m {k:v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m (k,v) \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     16\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m         inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Codes/VideoRecommender/utils.py:15\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_device\u001b[39m(inputs,device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     14\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs,\u001b[39mdict\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m         inputs \u001b[39m=\u001b[39m {k:v\u001b[39m.\u001b[39;49mto(device) \u001b[39mfor\u001b[39;00m (k,v) \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     16\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m         inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "result,prob_list = evaluate_full_metrics(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Sat Aug 20 12:02:09 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:21:00.0 Off |                  N/A |\n",
      "| 93%   75C    P2   320W / 350W |  23603MiB / 24576MiB |     94%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:22:00.0 Off |                  N/A |\n",
      "| 95%   76C    P2   331W / 350W |  23773MiB / 24576MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:41:00.0 Off |                  N/A |\n",
      "|100%   81C    P2   335W / 350W |  23805MiB / 24576MiB |     97%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  Off  | 00000000:43:00.0 Off |                  N/A |\n",
      "| 96%   77C    P2   325W / 350W |  24121MiB / 24576MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2066      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A    540551      C   .../envs/TracyEnv/bin/python    23595MiB |\n",
      "|    1   N/A  N/A      2066      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A    531953      C   .../envs/TracyEnv/bin/python    23765MiB |\n",
      "|    2   N/A  N/A      2066      G   /usr/lib/xorg/Xorg                106MiB |\n",
      "|    2   N/A  N/A      2557      G   /usr/bin/gnome-shell               45MiB |\n",
      "|    2   N/A  N/A    326196      C   python                          23649MiB |\n",
      "|    3   N/A  N/A      2066      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A    567469      C   python                          24113MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'threshold': 0.53379494,\n",
       " 'accuracy': 0.732,\n",
       " 'recall': 0.3225806451612903,\n",
       " 'precision': 0.6329113924050633,\n",
       " 'f1': 0.4273504273504274,\n",
       " 'auc': 0.718361947142127,\n",
       " 'eval_loss': 0.7405883215722584}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_save_dir,step,model_metrics):\n",
    "    model_save_dir = os.path.join(model_save_dir,f\"checkpoint-{step}\")\n",
    "    model_name = \"pytorch_model.bin\"\n",
    "    train_state_name = \"training_state.json\"\n",
    "    os.makedirs(model_save_dir,exist_ok=True)\n",
    "    \n",
    "    model_path = os.path.join(model_save_dir,model_name)\n",
    "    train_state_path = os.path.join(model_save_dir,train_state_name)\n",
    "\n",
    "    torch.save(model,model_path)\n",
    "    \n",
    "    if model_metrics is not None:\n",
    "        with open(train_state_path,mode = 'w',encoding = 'utf-8-sig') as f:\n",
    "            model_metrics = {str(k):str(v) for k,v in model_metrics.items()} \n",
    "            json.dump(model_metrics,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Training:   0%|          | 0/490 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************epoch: 1**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Evaluating: 100%|██████████| 42/42 [00:05<00:00,  7.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.189</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.297521</td>\n",
       "      <td>0.555263</td>\n",
       "      <td>0.44503</td>\n",
       "      <td>0.537698</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  accuracy    recall  precision        f1       auc  eval_loss  \\\n",
       "0      0.189      0.32  0.177778   0.911392  0.297521  0.555263    0.44503   \n",
       "\n",
       "   train_loss  steps  \n",
       "0    0.537698     32  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Evaluating: 100%|██████████| 42/42 [00:05<00:00,  7.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.16287</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.179293</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.298947</td>\n",
       "      <td>0.55585</td>\n",
       "      <td>0.435935</td>\n",
       "      <td>0.505945</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  accuracy    recall  precision        f1      auc  eval_loss  \\\n",
       "0    0.16287     0.334  0.179293   0.898734  0.298947  0.55585   0.435935   \n",
       "\n",
       "   train_loss  steps  \n",
       "0    0.505945     64  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Evaluating: 100%|██████████| 42/42 [00:05<00:00,  7.82it/s]\n",
      "/tmp/ipykernel_562866/255984957.py:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = recall*precision*2 / (recall + precision)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.12533</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.180412</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.299786</td>\n",
       "      <td>0.552948</td>\n",
       "      <td>0.438162</td>\n",
       "      <td>0.481268</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  accuracy    recall  precision        f1       auc  eval_loss  \\\n",
       "0    0.12533     0.346  0.180412   0.886076  0.299786  0.552948   0.438162   \n",
       "\n",
       "   train_loss  steps  \n",
       "0    0.481268     96  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Training:  20%|█▉        | 97/490 [00:48<09:38,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************epoch: 2**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Evaluating: 100%|██████████| 42/42 [00:05<00:00,  7.77it/s]\n",
      "/tmp/ipykernel_562866/255984957.py:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = recall*precision*2 / (recall + precision)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.237433</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.180412</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.299786</td>\n",
       "      <td>0.540666</td>\n",
       "      <td>0.457642</td>\n",
       "      <td>0.442531</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  accuracy    recall  precision        f1       auc  eval_loss  \\\n",
       "0   0.237433     0.346  0.180412   0.886076  0.299786  0.540666   0.457642   \n",
       "\n",
       "   train_loss  steps  \n",
       "0    0.442531    128  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Evaluating: 100%|██████████| 42/42 [00:05<00:00,  7.80it/s]\n",
      "/tmp/ipykernel_562866/255984957.py:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = recall*precision*2 / (recall + precision)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.175448</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.174334</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.527376</td>\n",
       "      <td>0.435514</td>\n",
       "      <td>0.458487</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  accuracy    recall  precision        f1       auc  eval_loss  \\\n",
       "0   0.175448     0.304  0.174334   0.911392  0.292683  0.527376   0.435514   \n",
       "\n",
       "   train_loss  steps  \n",
       "0    0.458487    160  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Training:  37%|███▋      | 181/490 [01:27<01:45,  2.92it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/nelson/Codes/VideoRecommender/4-training.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.112.110.123/home/nelson/Codes/VideoRecommender/4-training.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m probs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.112.110.123/home/nelson/Codes/VideoRecommender/4-training.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m BCELoss(probs,labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.112.110.123/home/nelson/Codes/VideoRecommender/4-training.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.112.110.123/home/nelson/Codes/VideoRecommender/4-training.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.112.110.123/home/nelson/Codes/VideoRecommender/4-training.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m train_losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_pbar = tqdm(total = len(train_loader)*train_config.epoches,desc = \"Model Training\",position=0, leave=True)\n",
    "\n",
    "total_batch = 0 \n",
    "for epoch in range(train_config.epoches):\n",
    "    print(\"*\"*50 + f\"epoch: {epoch + 1}\" + \"*\"*50)\n",
    "    \n",
    "    train_losses = []\n",
    "    \n",
    "    for inputs in train_loader:\n",
    "        model = model.train()\n",
    "        inputs = utils.to_device(inputs,train_config.device)\n",
    "        labels = inputs['label'].view(-1,1)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        probs = model(inputs)\n",
    "        \n",
    "        loss = BCELoss(probs,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if (total_batch+1) % train_config.eval_steps ==0:\n",
    "            model_metrics,_ = evaluate_full_metrics(model,test_loader)\n",
    "            train_loss = np.mean(train_losses)\n",
    "            model_metrics['train_loss'] = train_loss\n",
    "            model_metrics[\"steps\"] = total_batch+1\n",
    "        \n",
    "            save_model(model,train_config.model_save_dir,total_batch+1,model_metrics)\n",
    "            df_metrics_temp = pd.DataFrame([model_metrics])\n",
    "            display(df_metrics_temp)\n",
    "            \n",
    "            model = model.train()\n",
    "            \n",
    "        total_batch +=1\n",
    "        total_pbar.update(1)\n",
    "        \n",
    "total_pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6514ced458bdb201f5d3944e6ec87d786afec4746d32ceb81db15635ec0b0a7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
