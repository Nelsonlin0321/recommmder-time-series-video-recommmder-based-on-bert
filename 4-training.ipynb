{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import model_config\n",
    "from model import VedioRecommender\n",
    "from dataset import ViewDataSet\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from adamp import AdamP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VedioRecommender(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Read Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_dataset = utils.open_object(\"./artifacts/df_agg_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_duration</th>\n",
       "      <th>device_first_visit_age</th>\n",
       "      <th>user_age</th>\n",
       "      <th>video_start_hour</th>\n",
       "      <th>video_end_hour</th>\n",
       "      <th>platform_name</th>\n",
       "      <th>user_type</th>\n",
       "      <th>subscription_source</th>\n",
       "      <th>plan_platform</th>\n",
       "      <th>resolution</th>\n",
       "      <th>...</th>\n",
       "      <th>video_streaming_mode</th>\n",
       "      <th>cp_name</th>\n",
       "      <th>product_cat_name</th>\n",
       "      <th>product_lang_name</th>\n",
       "      <th>product_series_cms_id</th>\n",
       "      <th>next_sri_des</th>\n",
       "      <th>hist_sri_des</th>\n",
       "      <th>user_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.372071</td>\n",
       "      <td>0.387207</td>\n",
       "      <td>0.470131</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[7, 7, 7, 7, 7]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>...</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[43, 43, 43, 43, 43, 34]</td>\n",
       "      <td>[25, 25, 25, 25, 25, 6]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[169, 169, 169, 169, 169, 314]</td>\n",
       "      <td>A Jungle Survivor: Tang Ruo Qi (Rebecca Lim) i...</td>\n",
       "      <td>sri_des 1: Mr. Queen: Everyone who lives in a ...</td>\n",
       "      <td>1d0d24b9c6a703cc017342df93df5fee</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.371910</td>\n",
       "      <td>0.387207</td>\n",
       "      <td>0.470131</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[7, 7, 7, 7, 7]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>...</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[43, 43, 43, 43, 43, 62]</td>\n",
       "      <td>[25, 25, 25, 25, 25, 4]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 0]</td>\n",
       "      <td>[169, 169, 169, 169, 169, 133]</td>\n",
       "      <td>Sungkyunkwan Scandal: 金允熙为维持家计和赚取弟弟的医药费，迫于无奈女扮...</td>\n",
       "      <td>sri_des 1: Mr. Queen: Everyone who lives in a ...</td>\n",
       "      <td>1d0d24b9c6a703cc017342df93df5fee</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.371910</td>\n",
       "      <td>0.387207</td>\n",
       "      <td>0.470131</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[7, 7, 7, 7, 7]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>...</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[43, 43, 43, 43, 43, 35]</td>\n",
       "      <td>[25, 25, 25, 25, 25, 26]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[169, 169, 169, 169, 169, 707]</td>\n",
       "      <td>Be With You: Before her death, a woman promise...</td>\n",
       "      <td>sri_des 1: Mr. Queen: Everyone who lives in a ...</td>\n",
       "      <td>1d0d24b9c6a703cc017342df93df5fee</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.360397</td>\n",
       "      <td>0.387207</td>\n",
       "      <td>0.470131</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[7, 7, 7, 7, 7]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>...</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[43, 43, 43, 43, 36, 36]</td>\n",
       "      <td>[25, 25, 25, 25, 25, 25]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[169, 169, 169, 169, 984, 984]</td>\n",
       "      <td>Beyond Evil: Police inspectors are often the m...</td>\n",
       "      <td>sri_des 1: Mr. Queen: Everyone who lives in a ...</td>\n",
       "      <td>1d0d24b9c6a703cc017342df93df5fee</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.360397</td>\n",
       "      <td>0.387207</td>\n",
       "      <td>0.470131</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>[3, 3, 3, 3, 3]</td>\n",
       "      <td>[0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[7, 7, 7, 7, 7]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>...</td>\n",
       "      <td>[2, 2, 2, 2, 2]</td>\n",
       "      <td>[43, 43, 43, 43, 36, 28]</td>\n",
       "      <td>[25, 25, 25, 25, 25, 24]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[169, 169, 169, 169, 984, 243]</td>\n",
       "      <td>Ossan’s Love -in the sky-: [R21 — Mature Theme...</td>\n",
       "      <td>sri_des 1: Mr. Queen: Everyone who lives in a ...</td>\n",
       "      <td>1d0d24b9c6a703cc017342df93df5fee</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_duration  device_first_visit_age  user_age  video_start_hour  \\\n",
       "0          0.372071                0.387207  0.470131          0.623188   \n",
       "1          0.371910                0.387207  0.470131          0.623188   \n",
       "2          0.371910                0.387207  0.470131          0.623188   \n",
       "3          0.360397                0.387207  0.470131          0.543478   \n",
       "4          0.360397                0.387207  0.470131          0.543478   \n",
       "\n",
       "   video_end_hour    platform_name        user_type subscription_source  \\\n",
       "0        0.739130  [3, 3, 3, 3, 3]  [0, 0, 0, 0, 0]     [2, 2, 2, 2, 2]   \n",
       "1        0.666667  [3, 3, 3, 3, 3]  [0, 0, 0, 0, 0]     [2, 2, 2, 2, 2]   \n",
       "2        0.666667  [3, 3, 3, 3, 3]  [0, 0, 0, 0, 0]     [2, 2, 2, 2, 2]   \n",
       "3        0.456522  [3, 3, 3, 3, 3]  [0, 0, 0, 0, 0]     [2, 2, 2, 2, 2]   \n",
       "4        0.456522  [3, 3, 3, 3, 3]  [0, 0, 0, 0, 0]     [2, 2, 2, 2, 2]   \n",
       "\n",
       "     plan_platform       resolution  ... video_streaming_mode  \\\n",
       "0  [7, 7, 7, 7, 7]  [1, 1, 1, 1, 1]  ...      [2, 2, 2, 2, 2]   \n",
       "1  [7, 7, 7, 7, 7]  [1, 1, 1, 1, 1]  ...      [2, 2, 2, 2, 2]   \n",
       "2  [7, 7, 7, 7, 7]  [1, 1, 1, 1, 1]  ...      [2, 2, 2, 2, 2]   \n",
       "3  [7, 7, 7, 7, 7]  [1, 1, 1, 1, 1]  ...      [2, 2, 2, 2, 2]   \n",
       "4  [7, 7, 7, 7, 7]  [1, 1, 1, 1, 1]  ...      [2, 2, 2, 2, 2]   \n",
       "\n",
       "                    cp_name          product_cat_name   product_lang_name  \\\n",
       "0  [43, 43, 43, 43, 43, 34]   [25, 25, 25, 25, 25, 6]  [2, 2, 2, 2, 2, 2]   \n",
       "1  [43, 43, 43, 43, 43, 62]   [25, 25, 25, 25, 25, 4]  [2, 2, 2, 2, 2, 0]   \n",
       "2  [43, 43, 43, 43, 43, 35]  [25, 25, 25, 25, 25, 26]  [2, 2, 2, 2, 2, 2]   \n",
       "3  [43, 43, 43, 43, 36, 36]  [25, 25, 25, 25, 25, 25]  [2, 2, 2, 2, 2, 2]   \n",
       "4  [43, 43, 43, 43, 36, 28]  [25, 25, 25, 25, 25, 24]  [2, 2, 2, 2, 2, 2]   \n",
       "\n",
       "            product_series_cms_id  \\\n",
       "0  [169, 169, 169, 169, 169, 314]   \n",
       "1  [169, 169, 169, 169, 169, 133]   \n",
       "2  [169, 169, 169, 169, 169, 707]   \n",
       "3  [169, 169, 169, 169, 984, 984]   \n",
       "4  [169, 169, 169, 169, 984, 243]   \n",
       "\n",
       "                                        next_sri_des  \\\n",
       "0  A Jungle Survivor: Tang Ruo Qi (Rebecca Lim) i...   \n",
       "1  Sungkyunkwan Scandal: 金允熙为维持家计和赚取弟弟的医药费，迫于无奈女扮...   \n",
       "2  Be With You: Before her death, a woman promise...   \n",
       "3  Beyond Evil: Police inspectors are often the m...   \n",
       "4  Ossan’s Love -in the sky-: [R21 — Mature Theme...   \n",
       "\n",
       "                                        hist_sri_des  \\\n",
       "0  sri_des 1: Mr. Queen: Everyone who lives in a ...   \n",
       "1  sri_des 1: Mr. Queen: Everyone who lives in a ...   \n",
       "2  sri_des 1: Mr. Queen: Everyone who lives in a ...   \n",
       "3  sri_des 1: Mr. Queen: Everyone who lives in a ...   \n",
       "4  sri_des 1: Mr. Queen: Everyone who lives in a ...   \n",
       "\n",
       "                            user_id sequence_id label  \n",
       "0  1d0d24b9c6a703cc017342df93df5fee           4     0  \n",
       "1  1d0d24b9c6a703cc017342df93df5fee           7     0  \n",
       "2  1d0d24b9c6a703cc017342df93df5fee          10     0  \n",
       "3  1d0d24b9c6a703cc017342df93df5fee          18     1  \n",
       "4  1d0d24b9c6a703cc017342df93df5fee          20     0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_5_features = ['platform_name', 'user_type',\n",
    "       'subscription_source', 'plan_platform', 'resolution', 'subtitle',\n",
    "       'screen_mode', 'device_network_mode', 'video_streaming_mode']\n",
    "\n",
    "sequence_6_features = ['cp_name','product_cat_name', 'product_lang_name', 'product_series_cms_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sequence_5_features:\n",
    "    df_agg_dataset = df_agg_dataset[df_agg_dataset[col].apply(lambda x:len(x)==5)] \n",
    "\n",
    "for col in sequence_6_features:\n",
    "    df_agg_dataset = df_agg_dataset[df_agg_dataset[col].apply(lambda x:len(x)==6)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test = train_test_split(df_agg_dataset,test_size=0.3,random_state=33,shuffle = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ViewDataSet(df_train)\n",
    "test_dataset = ViewDataSet(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=12, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCELoss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = inputs['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6822, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BCELoss(scores,labels.view(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamP(model.parameters(),lr=4e-4,\n",
    "                  betas=(0.9, 0.999), weight_decay=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_config:\n",
    "    epoches = 5\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model_save_dir = \"./artifacts/models\"\n",
    "    train_batch_size = 12\n",
    "    val_batch_size = int(train_batch_size*1.5)\n",
    "    eval_steps = (len(train_dataset)//train_batch_size)//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Training:   0%|          | 0/490 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "total_pbar = tqdm(total = len(train_loader)*train_config.epoches,desc = \"Model Training\",position=0, leave=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_full_metrics(model,dataset_loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_list = []\n",
    "    labels_list = []\n",
    "    pred_list = []\n",
    "    prob_list = []\n",
    "\n",
    "    pbar = tqdm(total = len(dataset_loader),desc = \"Model Evaluating\",position=0, leave=True)\n",
    "\n",
    "\n",
    "    for inputs in dataset_loader:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            inputs = utils.to_device(inputs,train_config.device)\n",
    "            labels = inputs['label'].view(-1,1)\n",
    "            \n",
    "            probs = model(inputs)\n",
    "            \n",
    "            loss = BCELoss(probs,labels).item()\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            labels  = labels.detach().cpu().numpy()\n",
    "            labels_list.extend(labels.flatten())\n",
    "\n",
    "            probs = probs.detach().cpu().numpy()\n",
    "            prob_list.extend(probs.flatten())\n",
    "            pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    \n",
    "    auc = metrics.roc_auc_score(labels_list, prob_list)\n",
    "    recall, precision, thres = metrics.precision_recall_curve(labels_list, prob_list)\n",
    "    \n",
    "    \n",
    "    f1 = recall*precision*2 / (recall + precision)\n",
    "    f1_temp = f1\n",
    "    f1 = np.nan_to_num(f1,nan = -1)\n",
    "\n",
    "    arg = f1.argmax()\n",
    "    \n",
    "    best_thres = thres[arg]\n",
    "    best_f1 = f1[arg]\n",
    "    best_recall = recall[arg]\n",
    "    best_precision = precision[arg]\n",
    "    \n",
    "    pred_list = [1 if prob>=best_thres else 0 for prob in prob_list]\n",
    "    accuracy = metrics.accuracy_score(labels_list,pred_list)\n",
    "    \n",
    "    avg_loss = np.mean(loss_list)\n",
    "    \n",
    "    result = {\"threshold\":best_thres,\n",
    "              \"accuracy\":accuracy,\n",
    "              \"recall\":best_recall,\n",
    "              \"precision\":best_precision,\n",
    "              \"f1\":best_f1,'auc':auc,\n",
    "              'eval_loss':avg_loss} \n",
    "\n",
    "    return result,prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Evaluating: 100%|██████████| 42/42 [01:41<00:00,  2.42s/it]\n",
      "<ipython-input-22-9613067d0955>:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f1 = recall*precision*2 / (recall + precision)\n"
     ]
    }
   ],
   "source": [
    "result,prob_list = evaluate_full_metrics(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'threshold': 0.49956766,\n",
       " 'accuracy': 0.1536926147704591,\n",
       " 'recall': 0.152,\n",
       " 'precision': 1.0,\n",
       " 'f1': 0.2638888888888889,\n",
       " 'auc': 0.27975232198142413,\n",
       " 'eval_loss': 0.694588398649579}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_save_dir,step,model_metrics):\n",
    "    model_save_dir = os.path.join(model_save_dir,f\"checkpoint-{step}\")\n",
    "    model_name = \"pytorch_model.bin\"\n",
    "    train_state_name = \"training_state.json\"\n",
    "    os.makedirs(model_save_dir,exist_ok=True)\n",
    "    \n",
    "    model_path = os.path.join(model_save_dir,model_name)\n",
    "    train_state_path = os.path.join(model_save_dir,train_state_name)\n",
    "\n",
    "    torch.save(model,model_path)\n",
    "    \n",
    "    if model_metrics is not None:\n",
    "        with open(train_state_path,mode = 'w',encoding = 'utf-8-sig') as f:\n",
    "            model_metrics = {str(k):str(v) for k,v in model_metrics.items()} \n",
    "            json.dump(model_metrics,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Training:   0%|          | 0/490 [04:37<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [5] at entry 0 and [3] at entry 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/nlin/Desktop/Codes/local/VedioRecommender/4-training.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nlin/Desktop/Codes/local/VedioRecommender/4-training.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m idx\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nlin/Desktop/Codes/local/VedioRecommender/4-training.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nlin/Desktop/Codes/local/VedioRecommender/4-training.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     idx\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/torch/utils/data/dataloader.py:719\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    718\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 719\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    721\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:160\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    159\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: default_collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    161\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: default_collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:160\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    159\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: default_collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    161\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: default_collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m         storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    140\u001b[0m         out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n\u001b[1;32m    142\u001b[0m \u001b[39melif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstr_\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[1;32m    143\u001b[0m         \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring_\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmemmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    145\u001b[0m         \u001b[39m# array of string classes and object\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [5] at entry 0 and [3] at entry 10"
     ]
    }
   ],
   "source": [
    "idx=0\n",
    "for inputs in train_loader:\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Training:   0%|          | 0/490 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************epoch: 1**************************************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [5] at entry 0 and [3] at entry 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/nlin/Desktop/Codes/local/VedioRecommender/4-training.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nlin/Desktop/Codes/local/VedioRecommender/4-training.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m50\u001b[39m \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m50\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nlin/Desktop/Codes/local/VedioRecommender/4-training.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nlin/Desktop/Codes/local/VedioRecommender/4-training.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nlin/Desktop/Codes/local/VedioRecommender/4-training.ipynb#X42sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nlin/Desktop/Codes/local/VedioRecommender/4-training.ipynb#X42sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     inputs \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mto_device(inputs,train_config\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/torch/utils/data/dataloader.py:719\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    718\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 719\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    721\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:160\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    159\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: default_collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    161\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: default_collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:160\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    159\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: default_collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    161\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: default_collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch]) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/miniforge3/envs/mlp/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m         storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    140\u001b[0m         out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n\u001b[1;32m    142\u001b[0m \u001b[39melif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstr_\u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[1;32m    143\u001b[0m         \u001b[39mand\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mstring_\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m elem_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmemmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    145\u001b[0m         \u001b[39m# array of string classes and object\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [5] at entry 0 and [3] at entry 3"
     ]
    }
   ],
   "source": [
    "total_pbar = tqdm(total = len(train_loader)*train_config.epoches,desc = \"Model Training\",position=0, leave=True)\n",
    "\n",
    "total_batch = 0 \n",
    "for epoch in range(train_config.epoches):\n",
    "    print(\"*\"*50 + f\"epoch: {epoch + 1}\" + \"*\"*50)\n",
    "    \n",
    "    train_losses = []\n",
    "    \n",
    "    for inputs in train_loader:\n",
    "        model = model.train()\n",
    "        inputs = utils.to_device(inputs,train_config.device)\n",
    "        labels = inputs['label'].view(-1,1)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        probs = model(inputs)\n",
    "        \n",
    "        loss = BCELoss(probs,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if (total_batch+1) % train_config.eval_steps ==0:\n",
    "            model_metrics,_ = evaluate_full_metrics(model,test_loader)\n",
    "            train_loss = np.mean(train_losses)\n",
    "            model_metrics['train_loss'] = train_loss\n",
    "            model_metrics[\"steps\"] = total_batch+1\n",
    "        \n",
    "            save_model(model,train_config.model_save_dir,total_batch+1,model_metrics)\n",
    "            df_metrics_temp = pd.DataFrame([model_metrics])\n",
    "            display(df_metrics_temp)\n",
    "            \n",
    "            model = model.train()\n",
    "            \n",
    "    total_batch +=1\n",
    "    total_pbar.update(1)\n",
    "        \n",
    "total_pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b007d2981b7fc6aa14922b794f9b4f023f5cfd24ddc48922ef6cc62b5714e3d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
