{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel,AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = \"albert-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name, add_prefix_space=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_token = tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_dataset = utils.open_object(\"./artifacts/df_agg_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_scaler = utils.open_object(\"artifacts/numeric_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = list(numeric_scaler.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_value_map_dict = utils.open_object(\"./artifacts/col_value_to_index_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "catergory_features = list(category_value_map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = ['sri_des']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series = utils.open_object(\"./artifacts/series_table.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_features = set(list(df_series.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3) Dataset Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViewDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, df_agg_dataset):\n",
    "        self.df_agg_dataset = df_agg_dataset\n",
    "        self.len = len(df_agg_dataset)\n",
    "        self.non_text_features_label = numeric_features + catergory_features + ['label']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        index = [index]\n",
    "        \n",
    "        data_item = self.df_agg_dataset.iloc[index]    \n",
    "        \n",
    "        tokenized_inputs = tokenizer(\n",
    "            text = data_item['next_sri_des'].tolist(),\n",
    "            text_pair = data_item['hist_sri_des'].tolist(),\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        features_dict = data_item[self.non_text_features_label].to_dict(\"list\")\n",
    "        features_dict.update(tokenized_inputs)\n",
    "        features_dict = {k:torch.squeeze(torch.tensor(v)) for k,v in features_dict.items()}\n",
    "         \n",
    "        return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_dataset = ViewDataSet(df_agg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = view_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_dataset_loader = DataLoader(view_dataset, batch_size=18, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs in view_dataset_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "model_config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "model_config.num_lables = 2\n",
    "model_config.add_pooling_layer = False\n",
    "model_config.embedding_size = 4\n",
    "model_config.series_embedding_size = 16\n",
    "model_config.target_feature = 'product_series_cms_id' \n",
    "model_config.catergory_features = catergory_features\n",
    "model_config.numeric_features = numeric_features\n",
    "model_config.series_features = series_features\n",
    "model_config.bert_output_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class self:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.model_config = model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# self.catergory_features = self.model_config.catergory_features\n",
    "# self.numeric_features = self.model_config.numeric_features\n",
    "# self.series_features = self.model_config.series_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.bert = AutoModel.from_config(model_config,add_pooling_layer = self.model_config.add_pooling_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_encode = self.bert(input_ids=inputs['input_ids'],token_type_ids=inputs['token_type_ids'],\n",
    "          attention_mask=inputs['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.bert_linear = nn.Linear(self.model_config.hidden_size,self.model_config.bert_output_size, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 32])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_encode = bert_encode.last_hidden_state[:, 0]\n",
    "\n",
    "bert_encode = self.bert_linear(bert_encode)\n",
    "\n",
    "bert_encode.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.feature_embedding_dict = nn.ModuleDict()\n",
    "\n",
    "for feature in catergory_features:\n",
    "    if feature in self.model_config.series_features:\n",
    "        category_embeddings = nn.Embedding(len(category_value_map_dict[feature]), self.model_config.series_embedding_size)\n",
    "    else:\n",
    "        category_embeddings = nn.Embedding(len(category_value_map_dict[feature]), self.model_config.embedding_size)\n",
    "        \n",
    "    category_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "    self.feature_embedding_dict[feature] =category_embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (platform_name): Embedding(4, 4)\n",
       "  (user_type): Embedding(3, 4)\n",
       "  (subscription_source): Embedding(6, 4)\n",
       "  (plan_platform): Embedding(38, 4)\n",
       "  (resolution): Embedding(4, 4)\n",
       "  (subtitle): Embedding(13, 4)\n",
       "  (screen_mode): Embedding(3, 4)\n",
       "  (device_network_mode): Embedding(3, 4)\n",
       "  (video_streaming_mode): Embedding(3, 4)\n",
       "  (cp_name): Embedding(65, 16)\n",
       "  (product_cat_name): Embedding(40, 16)\n",
       "  (product_lang_name): Embedding(3, 16)\n",
       "  (product_series_cms_id): Embedding(1526, 16)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.feature_embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pool_concat_embedding(embeddings_value):\n",
    "    embeddings_hist_value = embeddings_value[:,:-1,:]\n",
    "    embeddings_next_value = embeddings_hist_value[:,-1,:]\n",
    "    embeddings_hist_mean_value = torch.mean(embeddings_hist_value,dim = 1)\n",
    "    embeddings_output = torch.concat(\n",
    "        (embeddings_hist_mean_value,embeddings_next_value),dim=1) \n",
    "\n",
    "    return embeddings_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_tensors_list = []\n",
    "for feature in self.model_config.catergory_features:\n",
    "    embedding_ids = inputs[feature]\n",
    "    \n",
    "    embedding_tensors = self.feature_embedding_dict[feature](embedding_ids)\n",
    "    if feature in self.model_config.series_features:\n",
    "        embedding_tensors = mean_pool_concat_embedding(embedding_tensors)\n",
    "    else:\n",
    "        embedding_tensors = torch.mean(embedding_tensors,dim = 1)\n",
    "        \n",
    "    embedding_tensors_list.append(embedding_tensors)\n",
    "\n",
    "embedding_features_tensors = torch.concat(embedding_tensors_list,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 164])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_features_tensors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_tensors_list = []\n",
    "for feature in self.model_config.numeric_features:\n",
    "    tensors  = inputs[feature].view(-1,1)\n",
    "    numeric_tensors_list.append(tensors)\n",
    "\n",
    "numeric_features_tesors = torch.concat(numeric_tensors_list,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,hidden_sizes,dropout = 0.1) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        mlp_list = []\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            mlp_list.append(nn.Linear(in_features=hidden_sizes[i],out_features=hidden_sizes[i+1],bias=True))\n",
    "            mlp_list.append(nn.LeakyReLU())\n",
    "            mlp_list.append(nn.Dropout(p=dropout))\n",
    "            \n",
    "        self.mlp = nn.Sequential(*mlp_list)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.mlp(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.mlp  = MLP(hidden_sizes=[201,128,32,16,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_input = torch.concat([bert_encode,embedding_features_tensors,numeric_features_tesors],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 201])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_encode = self.mlp(all_features_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.ranker = nn.Linear(in_features = 8,out_features  = 1,bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = self.ranker(features_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4450],\n",
       "        [0.4471],\n",
       "        [0.4445],\n",
       "        [0.4452],\n",
       "        [0.4433],\n",
       "        [0.4453],\n",
       "        [0.4452],\n",
       "        [0.4580],\n",
       "        [0.4579],\n",
       "        [0.4422],\n",
       "        [0.4496],\n",
       "        [0.4580],\n",
       "        [0.4441],\n",
       "        [0.4451],\n",
       "        [0.4443],\n",
       "        [0.4448],\n",
       "        [0.4452],\n",
       "        [0.4579]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = [201,64,32,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.bert_linear = nn.Linear(, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.mlp = nn.ModuleList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.activation_fuct = nn.functional.gelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VedioRecommender(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_config):\n",
    "        super().__init__()\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        self.catergory_features = model_config.catergory_features\n",
    "        self.numeric_features = model_config.numeric_features\n",
    "        \n",
    "        self.bert = AutoModel.from_config(model_config,add_pooling_layer = model_config.add_pooling_layer)\n",
    "        \n",
    "        self.feature_embedding_dict = {}\n",
    "        for feature in catergory_features:\n",
    "            if feature in self.series_features:\n",
    "                category_embeddings = nn.Embedding(len(category_value_map_dict[feature]), self.series_embedding_size)\n",
    "            else:\n",
    "                category_embeddings = nn.Embedding(len(category_value_map_dict[feature]), self.embedding_size)\n",
    "\n",
    "            category_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "            self.feature_embedding_dict[feature] =category_embeddings \n",
    "        \n",
    "        self.activation_fuct = nn.functional.gelu\n",
    "\n",
    "\n",
    "    def mean_pool_concatembedding(self,embeddings_value):\n",
    "        embeddings_hist_value = embeddings_value[:,:-1,:]\n",
    "        embeddings_next_value = embeddings_hist_value[:,-1,:]\n",
    "        embeddings_hist_mean_value = torch.mean(embeddings_hist_value,dim = 1)\n",
    "        embeddings_output = torch.concat(\n",
    "            (embeddings_hist_mean_value,embeddings_next_value),1) \n",
    "\n",
    "        return embeddings_output\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        # numeric feature\n",
    "        numeric_tensors_list = []\n",
    "        for feature in self.numeric_features:\n",
    "            tensors  = inputs[feature].view(-1,1)\n",
    "            numeric_tensors_list.append(tensors)\n",
    "            \n",
    "        numeric_features_tesors = torch.concat(numeric_tensors,dim=1)\n",
    "        \n",
    "        \n",
    "        # category embeedding features\n",
    "        embedding_tensors_list = []\n",
    "        for feature in self.catergory_features:\n",
    "            embedding_ids = inputs[feature]\n",
    "            embedding_tensors = self.feature_embedding_dict[feature](embedding_ids)\n",
    "            if feature in self.series_features:\n",
    "                embedding_tensors = mean_pool_concatembedding(embedding_tensors)\n",
    "            else:\n",
    "                embedding_tensors = torch.mean(embedding_tensors,dim = 1)\n",
    "            embedding_tensors_list.append(embedding_tensors)\n",
    "            \n",
    "        embedding_features_tensors = torch.concat(embedding_tensors_list,dim=1)\n",
    "        \n",
    "        \n",
    "        # text features\n",
    "        bert_encode = self.bert(input_ids=inputs['input_ids'],token_type_ids=inputs['token_type_ids'],\n",
    "                  attention_mask=inputs['attention_mask'])\n",
    "\n",
    "        bert_encode = bert_encode.last_hidden_state[:, 0]\n",
    "        bert_encode = self.bert_linear(bert_encode)\n",
    "        \n",
    "        \n",
    "        all_features = pd.concat((numeric_features_tesors,embedding_features_tensors,bert_encode),dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_name_embeddings_layer = nn.Embedding(len(category_value_map_dict['platform_name']), model_config.embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_name_embeddings_value = platform_name_embeddings_layer(platform_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pool_concatembedding(embeddings_value):\n",
    "    embeddings_hist_value = embeddings_value[:,:-1,:]\n",
    "    embeddings_next_value = embeddings_hist_value[:,-1,:]\n",
    "    embeddings_hist_mean_value = torch.mean(embeddings_hist_value,dim = 1)\n",
    "    embeddings_output = torch.concat(\n",
    "        (embeddings_hist_mean_value,embeddings_next_value),1) \n",
    "    \n",
    "    return embeddings_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 64])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pool_concat_embedding(platform_name_embeddings_value ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_name_embeddings_target_value = platform_name_embeddings_value[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 32])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platform_name_embeddings_target_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 5, 32])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platform_name_embeddings_hist_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_name_embeddings_hist_value = torch.mean(platform_name_embeddings_hist_value,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 32])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platform_name_embeddings_hist_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_name_embeddings_output = torch.concat(\n",
    "    (platform_name_embeddings_hist_value,platform_name_embeddings_target_value),1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 64])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platform_name_embeddings_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VedioRecommender(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        self.model_config = model_config\n",
    "        self.bert = AutoModel.from_config(model_config,add_pooling_layer = model_config.add_pooling_layer)\n",
    "        \n",
    "        self.linear = nn.Linear(model_config.hidden_size,model_config.model_embedding_size,bias = False)\n",
    "        \n",
    "        self.user_type_embeddings = nn.Embedding(len(category_value_map_dict['user_type']), model_config.embedding_size)\n",
    "        self.user_type_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "        \n",
    "        self.subscription_source_embeddings = nn.Embedding(len(category_value_map_dict['subscription_source']), model_config.embedding_size)\n",
    "        self.subscription_source_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "        \n",
    "        self.plan_platform_embeddings = nn.Embedding(len(category_value_map_dict['plan_platform']), model_config.embedding_size)\n",
    "        self.plan_platform_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "        \n",
    "        self.resolution_embeddings = nn.Embedding(len(category_value_map_dict['resolution']), model_config.embedding_size)\n",
    "        self.resolution_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "        \n",
    "        self.screen_mode_embeddings = nn.Embedding(len(category_value_map_dict['screen_mode']), model_config.embedding_size)\n",
    "        self.screen_mode_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "        \n",
    "        self.device_network_mode_embeddings = nn.Embedding(len(category_value_map_dict['device_network_mode']), model_config.embedding_size)\n",
    "        self.device_network_mode_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "        \n",
    "        self.video_streaming_mode_embeddings = nn.Embedding(len(category_value_map_dict['video_streaming_mode']), model_config.embedding_size)\n",
    "        self.video_streaming_mode_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "        \n",
    "        self.cp_name_embeddings = nn.Embedding(len(category_value_map_dict['cp_name']), model_config.embedding_size)\n",
    "        self.cp_name_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "        \n",
    "        self.product_cat_name_embeddings = nn.Embedding(len(category_value_map_dict['product_cat_name']), model_config.embedding_size)\n",
    "        self.user_type_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "        \n",
    "        self.product_lang_name_embeddings = nn.Embedding(len(category_value_map_dict['product_lang_name']), model_config.embedding_size)\n",
    "        self.product_lang_name_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "        \n",
    "        self.product_series_cms_id_embeddings = nn.Embedding(len(category_value_map_dict['product_series_cms_id']), model_config.embedding_size)\n",
    "        self.product_series_cms_id_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "\n",
    "\n",
    "    def mean_pool_concatembedding(self,embeddings_value):\n",
    "        embeddings_hist_value = embeddings_value[:,:-1,:]\n",
    "        embeddings_next_value = embeddings_hist_value[:,-1,:]\n",
    "        embeddings_hist_mean_value = torch.mean(embeddings_hist_value,dim = 1)\n",
    "        embeddings_output = torch.concat(\n",
    "            (embeddings_hist_mean_value,embeddings_next_value),1) \n",
    "\n",
    "        return embeddings_output\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        #numeric features\n",
    "        episode_duration  = inputs['episode_duration'].view(-1,1)\n",
    "        device_first_visit_age = inputs['device_first_visit_age'].view(-1,1)\n",
    "        user_age = inputs['user_age'].view(-1,1)\n",
    "        video_start_hour = inputs['video_start_hour'].view(-1,1)\n",
    "        video_end_hour = inputs['video_end_hour'].view(-1,1)\n",
    "        \n",
    "        \n",
    "        numeric_features = torch.concat(\n",
    "            (episode_duration,device_first_visit_age,user_age,video_start_hour,video_end_hour),\n",
    "            dim=1)\n",
    "        \n",
    "\n",
    "        # embedding feature\n",
    "        platform_name_inputs = inputs['platform_name']\n",
    "        plan_platform_embeddings = self.plan_platform_embeddings(platform_name_inputs)\n",
    "        plan_platform_embeddings = mean_pool_concatembedding(plan_platform_embeddings)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        encoder_outputs = self.bert(**inputs)\n",
    "\n",
    "        sequence_output = encoder_outputs[0]\n",
    "\n",
    "        last_hidden_state = sequence_output[:, 0]\n",
    "        \n",
    "        bert_encode = self.linear(last_hidden_state)\n",
    "        \n",
    "        logits = None\n",
    "        total_loss= None\n",
    "        pos_loss, neg_bert_loss = None, None\n",
    "        \n",
    "        if output_logit:\n",
    "            logits = torch.matmul(bert_encode,self.embeddings.weight.transpose(0, 1))\n",
    "        \n",
    "        if labels is not None:\n",
    "            batch_size = inputs['input_ids'].shape[0]\n",
    "            \n",
    "            negative_samples = self.take_negative_samples(self.num_lables,\n",
    "                                  self.negative_sample_size,\n",
    "                                  batch_size,\n",
    "                                  self.sampling_prob_dist).to(self.device)\n",
    "                \n",
    "            \n",
    "            neg_embed = self.embeddings(negative_samples) # torch.Size([18, 2048, 256])\n",
    "            label_embed = self.embeddings(labels) # torch.Size([18, 256])\n",
    "            \n",
    "            # positive\n",
    "            # torch.Size([18, 256]) * torch.Size([18, 256])\n",
    "            pos_bert_logits = torch.diag(torch.matmul(label_embed, bert_encode.transpose(0, 1)))\n",
    "            pos_bert_loss = -torch.log(1 / (1 + torch.exp(-pos_bert_logits))).mean()\n",
    "            \n",
    "            # negative\n",
    "            # torch.Size([18, 2048, 256]) * torch.Size([18, 256])\n",
    "            neg_bert_logits = torch.matmul(neg_embed, torch.unsqueeze(bert_encode, dim=-1)).squeeze()\n",
    "            neg_bert_loss = -torch.log(1 / (1 + torch.exp(neg_bert_logits))).mean()\n",
    "\n",
    "            total_loss = 5*pos_bert_loss + neg_bert_loss\n",
    "                \n",
    "        \n",
    "        return ModelOutput(total_loss,pos_bert_loss,neg_bert_loss,bert_encode,logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b007d2981b7fc6aa14922b794f9b4f023f5cfd24ddc48922ef6cc62b5714e3d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
