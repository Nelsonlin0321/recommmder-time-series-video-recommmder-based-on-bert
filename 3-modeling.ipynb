{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel,AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = \"albert-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name, add_prefix_space=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_token = tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_dataset = utils.open_object(\"./artifacts/df_agg_dataset.pkl\")\n",
    "numeric_scaler = utils.open_object(\"artifacts/numeric_scaler.pkl\")\n",
    "numeric_features = list(numeric_scaler.feature_names_in_)\n",
    "category_value_map_dict = utils.open_object(\"./artifacts/col_value_to_index_dict.pkl\")\n",
    "catergory_features = list(category_value_map_dict)\n",
    "text_features = ['sri_des']\n",
    "df_series = utils.open_object(\"./artifacts/series_table.pkl\")\n",
    "series_features = set(list(df_series.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViewDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, df_agg_dataset):\n",
    "        self.df_agg_dataset = df_agg_dataset\n",
    "        self.len = len(df_agg_dataset)\n",
    "        self.non_text_features_label = numeric_features + catergory_features + ['label']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        index = [index]\n",
    "        \n",
    "        data_item = self.df_agg_dataset.iloc[index]    \n",
    "        \n",
    "        tokenized_inputs = tokenizer(\n",
    "            text = data_item['next_sri_des'].tolist(),\n",
    "            text_pair = data_item['hist_sri_des'].tolist(),\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        features_dict = data_item[self.non_text_features_label].to_dict(\"list\")\n",
    "        features_dict.update(tokenized_inputs)\n",
    "        features_dict = {k:torch.squeeze(torch.tensor(v)) for k,v in features_dict.items()}\n",
    "         \n",
    "        return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_dataset = ViewDataSet(df_agg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = view_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_dataset_loader = DataLoader(view_dataset, batch_size=18, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs in view_dataset_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "model_config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "model_config.num_lables = 2\n",
    "model_config.add_pooling_layer = False\n",
    "model_config.embedding_size = 4\n",
    "model_config.series_embedding_size = 16\n",
    "model_config.target_feature = 'product_series_cms_id' \n",
    "model_config.catergory_features = catergory_features\n",
    "model_config.numeric_features = numeric_features\n",
    "model_config.series_features = series_features\n",
    "model_config.bert_output_size = 32\n",
    "model_config.hidden_sizes = [201,128,64,32]\n",
    "model_config.dropout = 0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,hidden_sizes,dropout = 0.1) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        mlp_list = []\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            mlp_list.append(nn.Linear(in_features=hidden_sizes[i],out_features=hidden_sizes[i+1],bias=True))\n",
    "            mlp_list.append(nn.LeakyReLU())\n",
    "            mlp_list.append(nn.Dropout(p=dropout))\n",
    "            \n",
    "        self.mlp = nn.Sequential(*mlp_list)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.mlp(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoRecommender(nn.Module):\n",
    "    def __init__(self,model_config):\n",
    "        super().__init__()\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model_config  = model_config\n",
    "        \n",
    "        # bert\n",
    "        self.bert = AutoModel.from_config(model_config)\n",
    "        self.bert_linear = nn.Linear(self.model_config.hidden_size,self.model_config.bert_output_size, bias=False)\n",
    "        \n",
    "        # category embedding\n",
    "        self.feature_embedding_dict = nn.ModuleDict()\n",
    "        for feature in catergory_features:\n",
    "            if feature in self.model_config.series_features:\n",
    "                category_embeddings = nn.Embedding(len(category_value_map_dict[feature]), self.model_config.series_embedding_size)\n",
    "            else:\n",
    "                category_embeddings = nn.Embedding(len(category_value_map_dict[feature]), self.model_config.embedding_size)\n",
    "                \n",
    "            category_embeddings.weight.data.uniform_(-0.5,-0.5)\n",
    "            self.feature_embedding_dict[feature] =category_embeddings\n",
    "            \n",
    "        # mlp\n",
    "        self.mlp = MLP(self.model_config.hidden_sizes,dropout=self.model_config.dropout)\n",
    "        \n",
    "        self.ranker = nn.Linear(in_features = self.model_config.hidden_sizes[-1],\n",
    "                                out_features  = 1,bias=True)\n",
    "\n",
    "    def mean_pool_concat_embedding(self,embeddings_value):\n",
    "        embeddings_hist_value = embeddings_value[:,:-1,:]\n",
    "        embeddings_next_value = embeddings_hist_value[:,-1,:]\n",
    "        embeddings_hist_mean_value = torch.mean(embeddings_hist_value,dim = 1)\n",
    "        embeddings_output = torch.concat(\n",
    "            (embeddings_hist_mean_value,embeddings_next_value),dim=1) \n",
    "\n",
    "        return embeddings_output\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        # bert\n",
    "        bert_encode = self.bert(input_ids=inputs['input_ids'],\n",
    "                                token_type_ids=inputs['token_type_ids'],\n",
    "                                attention_mask=inputs['attention_mask'])\n",
    "        bert_encode = bert_encode.last_hidden_state[:, 0]\n",
    "        bert_encode = self.bert_linear(bert_encode)\n",
    "        \n",
    "\n",
    "        # embedding\n",
    "        embedding_tensors_list = []\n",
    "        for feature in self.model_config.catergory_features:\n",
    "            embedding_ids = inputs[feature]\n",
    "            \n",
    "            embedding_tensors = self.feature_embedding_dict[feature](embedding_ids)\n",
    "            if feature in self.model_config.series_features:\n",
    "                embedding_tensors = self.mean_pool_concat_embedding(embedding_tensors)\n",
    "            else:\n",
    "                embedding_tensors = torch.mean(embedding_tensors,dim = 1)\n",
    "                \n",
    "            embedding_tensors_list.append(embedding_tensors)\n",
    "\n",
    "        embedding_encode = torch.concat(embedding_tensors_list,dim=1)\n",
    "        \n",
    "        #numeric\n",
    "        numeric_tensors_list = []\n",
    "        for feature in self.model_config.numeric_features:\n",
    "            tensors  = inputs[feature].view(-1,1)\n",
    "            numeric_tensors_list.append(tensors)\n",
    "\n",
    "        numeric_encode = torch.concat(numeric_tensors_list,dim=1)\n",
    "        \n",
    "        all_features_encode = torch.concat(\n",
    "            [bert_encode,embedding_encode,numeric_encode],\n",
    "            dim=1)\n",
    "        \n",
    "        all_features_encode = self.mlp(all_features_encode)\n",
    "        \n",
    "        scores = self.ranker(all_features_encode)\n",
    "        \n",
    "        scores = torch.sigmoid(scores)\n",
    "        \n",
    "        return scores\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_recommender = VideoRecommender(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VedioRecommender(\n",
       "  (bert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 4, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 4)\n",
       "      (token_type_embeddings): Embedding(2, 4)\n",
       "      (LayerNorm): LayerNorm((4,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=4, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (bert_linear): Linear(in_features=768, out_features=32, bias=False)\n",
       "  (feature_embedding_dict): ModuleDict(\n",
       "    (platform_name): Embedding(4, 4)\n",
       "    (user_type): Embedding(3, 4)\n",
       "    (subscription_source): Embedding(6, 4)\n",
       "    (plan_platform): Embedding(38, 4)\n",
       "    (resolution): Embedding(4, 4)\n",
       "    (subtitle): Embedding(13, 4)\n",
       "    (screen_mode): Embedding(3, 4)\n",
       "    (device_network_mode): Embedding(3, 4)\n",
       "    (video_streaming_mode): Embedding(3, 4)\n",
       "    (cp_name): Embedding(65, 16)\n",
       "    (product_cat_name): Embedding(40, 16)\n",
       "    (product_lang_name): Embedding(3, 16)\n",
       "    (product_series_cms_id): Embedding(1526, 16)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=201, out_features=128, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (4): LeakyReLU(negative_slope=0.01)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (7): LeakyReLU(negative_slope=0.01)\n",
       "      (8): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ranker): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = video_recommender(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5245],\n",
       "        [0.5255],\n",
       "        [0.5264],\n",
       "        [0.5246],\n",
       "        [0.5236],\n",
       "        [0.5269],\n",
       "        [0.5276],\n",
       "        [0.5268],\n",
       "        [0.5236],\n",
       "        [0.5278],\n",
       "        [0.5280],\n",
       "        [0.5237],\n",
       "        [0.5240],\n",
       "        [0.5290],\n",
       "        [0.5235],\n",
       "        [0.5249],\n",
       "        [0.5204],\n",
       "        [0.5219]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b007d2981b7fc6aa14922b794f9b4f023f5cfd24ddc48922ef6cc62b5714e3d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
